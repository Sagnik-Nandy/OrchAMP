{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4263743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/combined_reconstruction_errors_original_scale_with_SE_new_set_up.csv\n"
     ]
    }
   ],
   "source": [
    "# This script shall be used to combine the results from the cluster nodes and create the final metric reported in the manuscript. This code assumes that the individual CSV files have already been generated by the experiment scripts. \n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Setup directory ===\n",
    "results_dir = \"/home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration\"  # <-- UPDATE THIS PATH\n",
    "pattern = os.path.join(results_dir, \"reconstruction_*_lam*_rho*.csv\")\n",
    "all_csvs = sorted(glob.glob(pattern))\n",
    "csv_files = [fn for fn in all_csvs if \"_iters\" not in os.path.basename(fn)]\n",
    "\n",
    "N_TRIALS = 50\n",
    "EPS = 0.0  # if your metric must be nonnegative, keep 0.0; change if needed\n",
    "\n",
    "records = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        setting = row[\"setting\"]\n",
    "        # Replace setting labels using Unicode\n",
    "        if setting == \"std\":\n",
    "            setting = \"γ₂ = 0.25\"\n",
    "        elif setting == \"sparse\":\n",
    "            setting = \"γ₂ = 0.05\"\n",
    "\n",
    "        lam = float(row[\"lambda\"])\n",
    "        rho = float(row[\"rho\"])\n",
    "\n",
    "        method_map = {\n",
    "            \"E1_joint\": (\"Modality 1\", \"Joint AMP\"),\n",
    "            \"E2_joint\": (\"Modality 2\", \"Joint AMP\"),\n",
    "            \"E3_joint\": (\"Modality 3\", \"Joint AMP\"),\n",
    "            \"E1_sep\":   (\"Modality 1\", \"Separate AMP\"),\n",
    "            \"E2_sep\":   (\"Modality 2\", \"Separate AMP\"),\n",
    "            \"E3_sep\":   (\"Modality 3\", \"Separate AMP\"),\n",
    "            \"E1_svd\":   (\"Modality 1\", \"SVD\"),\n",
    "            \"E2_svd\":   (\"Modality 2\", \"SVD\"),\n",
    "            \"E3_svd\":   (\"Modality 3\", \"SVD\"),\n",
    "            \"E2ab_joint\": (\"Modality 2 first two cols\", \"Joint AMP\"),\n",
    "            \"E2ab_sep\":   (\"Modality 2 first two cols\", \"Separate AMP\"),\n",
    "            \"E2ab_svd\":   (\"Modality 2 first two cols\", \"SVD\"),\n",
    "            \"E2ab_joint_std\": (\"Modality 2 first two cols\", \"Joint AMP\"),\n",
    "            \"E2ab_sep_std\":   (\"Modality 2 first two cols\", \"Separate AMP\"),\n",
    "            \"E2ab_svd_std\":   (\"Modality 2 first two cols\", \"SVD\"),\n",
    "        }\n",
    "        \n",
    "        for base_col, (modality, method) in method_map.items():\n",
    "            # Standardize per-modality if desired (kept from your code)\n",
    "            divisor = 2 if modality == \"Modality 1\" else 3 if modality == \"Modality 2\" else 2\n",
    "\n",
    "            # Mean reconstruction error on ORIGINAL scale (no log)\n",
    "            mean_val = row[base_col] / divisor\n",
    "\n",
    "            # Convert stored std to standard error\n",
    "            std_col = base_col + \"_std\"\n",
    "            if std_col in df.columns and pd.notna(row.get(std_col, np.nan)):\n",
    "                std_val = row[std_col] / divisor\n",
    "                se_val = std_val / np.sqrt(N_TRIALS)\n",
    "                # ±2 SE bands on ORIGINAL scale\n",
    "                ci_lb = max(mean_val - 2 * se_val, EPS)\n",
    "                ci_ub = mean_val + 2 * se_val\n",
    "            else:\n",
    "                se_val = np.nan\n",
    "                ci_lb = np.nan\n",
    "                ci_ub = np.nan\n",
    "\n",
    "            records.append({\n",
    "                \"Modality\": modality,\n",
    "                \"Method\": method,\n",
    "                \"lam\": lam,\n",
    "                \"rho\": rho,\n",
    "                \"setting\": setting,\n",
    "                \"rec_error_mean\": mean_val,\n",
    "                \"rec_error_se\": se_val,\n",
    "                \"rec_error_ci_lb\": ci_lb,\n",
    "                \"rec_error_ci_ub\": ci_ub,\n",
    "            })\n",
    "\n",
    "# === Create final DataFrame ===\n",
    "final_df = pd.DataFrame(records)\n",
    "\n",
    "# === Save to CSV ===\n",
    "out_path = os.path.join(results_dir, \"combined_reconstruction_errors_original_scale_with_SE_new_set_up.csv\")\n",
    "final_df.to_csv(out_path, index=False)\n",
    "print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c6a6fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_1_lambda_by_rho_landscape.tex\n",
      "Wrote: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_2_lambda_by_rho_landscape.tex\n",
      "Wrote: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_2_first_two_cols_lambda_by_rho_landscape.tex\n",
      "Wrote: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_3_lambda_by_rho_landscape.tex\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# ======= USER CONFIG =======\n",
    "combined_csv = \"/home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/combined_reconstruction_errors_original_scale_with_SE_new_set_up.csv\"  # <-- UPDATE THIS PATH\n",
    "out_dir = os.path.dirname(combined_csv)\n",
    "\n",
    "# Columns (rho) order shown across the table\n",
    "RHO_ORDER: List[float] = [0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "# Row groups (lambda) — set to None to auto-detect & sort\n",
    "LAMBDA_ORDER: List[float] | None = None\n",
    "\n",
    "# Formatting\n",
    "MEAN_FMT = \"{:.6f}\"   # mean to SIX decimals\n",
    "SE_FMT   = \"{:.6f}\"\n",
    "METHOD_ORDER = [\"Joint AMP\", \"Separate AMP\", \"SVD\"]\n",
    "PANELS = [\"γ₂ = 0.05\", \"γ₂ = 0.25\"]  # top then bottom\n",
    "TABCOLSEP_PT = 3      # smaller = tighter columns\n",
    "ARRAY_STRETCH = 0.9   # <1 = tighter rows\n",
    "FONTSIZE_CMD = \"\\\\scriptsize\"  # or \\\\footnotesize\n",
    "\n",
    "# ======= LOAD =======\n",
    "df = pd.read_csv(combined_csv)\n",
    "df[\"lam\"] = df[\"lam\"].astype(float)\n",
    "df[\"rho\"] = df[\"rho\"].astype(float)\n",
    "\n",
    "def fmt_cell(mean: float, se: float, bold: bool) -> str:\n",
    "    s = f\"{MEAN_FMT.format(mean)} ({SE_FMT.format(se)})\"\n",
    "    return f\"\\\\textbf{{{s}}}\" if bold else s\n",
    "\n",
    "def panel_block(df_mod: pd.DataFrame, setting: str,\n",
    "                lambda_order: List[float], rho_order: List[float]) -> str:\n",
    "    sub = df_mod[df_mod[\"setting\"] == setting].copy()\n",
    "    if sub.empty:\n",
    "        return \"\"  # skip if panel missing\n",
    "\n",
    "    lines: List[str] = []\n",
    "    lines.append(\"\\\\midrule\")\n",
    "    lines.append(f\"\\\\multicolumn{{{1+len(rho_order)}}}{{l}}{{\\\\textit{{Setting: {setting}}}}}\\\\\\\\\")\n",
    "    lines.append(\"\\\\midrule\")\n",
    "\n",
    "    # Header: blank corner + rho columns\n",
    "    header = [\" \"]\n",
    "    header += [f\"$\\\\rho={r:g}$\" for r in rho_order]\n",
    "    lines.append(\" & \".join(header) + \" \\\\\\\\\")\n",
    "    lines.append(\"\\\\midrule\")\n",
    "\n",
    "    for lam in lambda_order:\n",
    "        # determine best method per rho at this lambda\n",
    "        best_idx_for_rho = []\n",
    "        for rho in rho_order:\n",
    "            trip = sub[(sub[\"lam\"] == lam) & (sub[\"rho\"] == rho)]\n",
    "            means = []\n",
    "            for m in METHOD_ORDER:\n",
    "                rec = trip[trip[\"Method\"] == m]\n",
    "                means.append(float(rec[\"rec_error_mean\"].values[0]) if not rec.empty else float(\"inf\"))\n",
    "            best_idx_for_rho.append(int(pd.Series(means).idxmin()))\n",
    "\n",
    "        # three sub-rows: Joint, Separate, SVD\n",
    "        for mi, method in enumerate(METHOD_ORDER):\n",
    "            # first column: multirow lambda on the first of the three rows,\n",
    "            # with the method name printed in that same cell (your sketch)\n",
    "            if mi == 0:\n",
    "                first_cell = f\"\\\\multirow{{3}}{{*}}{{\\\\(\\\\lambda={lam:g}\\\\)\\\\\\\\ {method}}}\"\n",
    "            else:\n",
    "                first_cell = method  # subsequent lines: just the method name in the first column\n",
    "\n",
    "            row_cells = [first_cell]\n",
    "            for ci, rho in enumerate(rho_order):\n",
    "                rec = sub[(sub[\"lam\"] == lam) & (sub[\"rho\"] == rho) & (sub[\"Method\"] == method)]\n",
    "                if rec.empty:\n",
    "                    row_cells.append(\"--\")\n",
    "                else:\n",
    "                    mean = float(rec[\"rec_error_mean\"].values[0])\n",
    "                    se   = float(rec[\"rec_error_se\"].values[0])\n",
    "                    row_cells.append(fmt_cell(mean, se, bold=(best_idx_for_rho[ci] == mi)))\n",
    "            lines.append(\" & \".join(row_cells) + \" \\\\\\\\\")\n",
    "        lines.append(\"\\\\addlinespace[2pt]\")  # small gap between lambda blocks\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def make_landscape_table(df: pd.DataFrame, modality: str) -> str:\n",
    "    df_mod = df[df[\"Modality\"] == modality].copy()\n",
    "    if df_mod.empty:\n",
    "        return \"\"\n",
    "\n",
    "    # establish orders\n",
    "    lambda_order = sorted(df_mod[\"lam\"].unique().tolist()) if LAMBDA_ORDER is None else LAMBDA_ORDER\n",
    "    rho_order = [r for r in RHO_ORDER if r in set(df_mod[\"rho\"].unique())]\n",
    "\n",
    "    tabspec = \"@{}l\" + \"c\"*len(rho_order) + \"@{}\"   # 1 left column + rho columns, tight margins\n",
    "\n",
    "    lines: List[str] = []\n",
    "    lines.append(\"% Requires: \\\\usepackage{booktabs,multirow,pdflscape}\")\n",
    "    lines.append(\"\\\\begin{landscape}\")\n",
    "    lines.append(\"\\\\begin{table}[p]\")\n",
    "    lines.append(\"\\\\centering\")\n",
    "    lines.append(FONTSIZE_CMD)\n",
    "    lines.append(f\"\\\\setlength{{\\\\tabcolsep}}{{{TABCOLSEP_PT}pt}}\")\n",
    "    lines.append(f\"\\\\renewcommand{{\\\\arraystretch}}{{{ARRAY_STRETCH}}}\")\n",
    "    lines.append(f\"\\\\begin{{tabular}}{{{tabspec}}}\")\n",
    "    lines.append(\"\\\\toprule\")\n",
    "\n",
    "    wrote_any = False\n",
    "    for setting in PANELS:\n",
    "        blk = panel_block(df_mod, setting, lambda_order, rho_order)\n",
    "        if blk:\n",
    "            lines.append(blk)\n",
    "            wrote_any = True\n",
    "\n",
    "    lines.append(\"\\\\bottomrule\")\n",
    "    lines.append(\"\\\\end{tabular}\")\n",
    "    cap = (f\"Reconstruction error (SE) for {modality} with columns indexed by $\\\\rho$ \"\n",
    "           f\"and rows grouped by $\\\\lambda$ (three sub-rows: Joint AMP, Separate AMP, SVD). \"\n",
    "           f\"Best (lowest mean) bolded. Top panel $\\\\gamma_2=0.05$, bottom panel $\\\\gamma_2=0.25$.\")\n",
    "    lab = f\"tab:{modality.lower().replace(' ', '_')}_lambda_by_rho\"\n",
    "    lines.append(f\"\\\\caption{{{cap}}}\")\n",
    "    lines.append(f\"\\\\label{{{lab}}}\")\n",
    "    lines.append(\"\\\\end{table}\")\n",
    "    lines.append(\"\\\\end{landscape}\")\n",
    "\n",
    "    return \"\\n\".join(lines) if wrote_any else \"\"\n",
    "\n",
    "# ======= WRITE FILES =======\n",
    "for modality in sorted(df[\"Modality\"].unique()):\n",
    "    tex = make_landscape_table(df, modality)\n",
    "    if tex:\n",
    "        out_path = os.path.join(out_dir, f\"{modality.lower().replace(' ', '_')}_lambda_by_rho_landscape.tex\")\n",
    "        with open(out_path, \"w\") as f:\n",
    "            f.write(tex)\n",
    "        print(f\"Wrote: {out_path}\")\n",
    "    else:\n",
    "        print(f\"[WARN] No data for modality: {modality}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fd86e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved panel CSV: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_1_gamma2_=_0.05_panel.csv\n",
      "Saved panel CSV: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_1_gamma2_=_0.25_panel.csv\n",
      "Saved panel CSV: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_2_gamma2_=_0.05_panel.csv\n",
      "Saved panel CSV: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_2_gamma2_=_0.25_panel.csv\n",
      "Saved panel CSV: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_2_first_two_cols_gamma2_=_0.05_panel.csv\n",
      "Saved panel CSV: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_2_first_two_cols_gamma2_=_0.25_panel.csv\n",
      "Saved panel CSV: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_3_gamma2_=_0.05_panel.csv\n",
      "Saved panel CSV: /home/nandy.15/Research/Experiments_revision/Results/Effect_of_data_integration/modality_3_gamma2_=_0.25_panel.csv\n"
     ]
    }
   ],
   "source": [
    "def make_panel_dataframe(df, modality, setting, lambda_order, rho_order):\n",
    "    sub = df[(df[\"Modality\"] == modality) & (df[\"setting\"] == setting)].copy()\n",
    "    if sub.empty:\n",
    "        return None\n",
    "\n",
    "    # Prepare multi-index for rows: (lambda, method)\n",
    "    index = []\n",
    "    data = []\n",
    "    for lam in lambda_order:\n",
    "        trip = sub[sub[\"lam\"] == lam]\n",
    "        # Find best method per rho\n",
    "        best_idx_for_rho = []\n",
    "        for rho in rho_order:\n",
    "            means = []\n",
    "            for m in METHOD_ORDER:\n",
    "                rec = trip[(trip[\"Method\"] == m) & (trip[\"rho\"] == rho)]\n",
    "                means.append(float(rec[\"rec_error_mean\"].values[0]) if not rec.empty else float(\"inf\"))\n",
    "            best_idx_for_rho.append(int(pd.Series(means).idxmin()))\n",
    "        for mi, method in enumerate(METHOD_ORDER):\n",
    "            index.append((lam, method))\n",
    "            row = []\n",
    "            for ci, rho in enumerate(rho_order):\n",
    "                rec = sub[(sub[\"lam\"] == lam) & (sub[\"rho\"] == rho) & (sub[\"Method\"] == method)]\n",
    "                if rec.empty:\n",
    "                    row.append(\"--\")\n",
    "                else:\n",
    "                    mean = float(rec[\"rec_error_mean\"].values[0])\n",
    "                    se = float(rec[\"rec_error_se\"].values[0])\n",
    "                    cell = f\"{mean:.6f} ({se:.6f})\"\n",
    "                    # Mark best method with asterisk\n",
    "                    if best_idx_for_rho[ci] == mi:\n",
    "                        cell += \" *\"\n",
    "                    row.append(cell)\n",
    "            data.append(row)\n",
    "    df_panel = pd.DataFrame(data, index=pd.MultiIndex.from_tuples(index, names=[\"lambda\", \"method\"]), columns=[f\"rho={r:g}\" for r in rho_order])\n",
    "    return df_panel\n",
    "\n",
    "# Example usage for all modalities and settings:\n",
    "dfs = {}\n",
    "lambda_order = sorted(df[\"lam\"].unique().tolist()) if LAMBDA_ORDER is None else LAMBDA_ORDER\n",
    "rho_order = [r for r in RHO_ORDER if r in set(df[\"rho\"].unique())]\n",
    "for modality in sorted(df[\"Modality\"].unique()):\n",
    "    for setting in PANELS:\n",
    "        panel_df = make_panel_dataframe(df, modality, setting, lambda_order, rho_order)\n",
    "        if panel_df is not None:\n",
    "            dfs[(modality, setting)] = panel_df\n",
    "            # Save each panel DataFrame to CSV\n",
    "            csv_name = f'{modality.lower().replace(' ', '_')}_{setting.replace(' ', '_').replace('γ₂', 'gamma2')}_panel.csv'\n",
    "            csv_path = os.path.join(results_dir, csv_name)\n",
    "            panel_df.to_csv(csv_path)\n",
    "            print(f'Saved panel CSV: {csv_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f15d20",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_amp_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
